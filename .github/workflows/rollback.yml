name: Database Rollback

on:
  workflow_dispatch:
    inputs:
      backup_file:
        description: 'Backup filename (e.g., backup-2026-01-13.sql.gz.gpg) or "latest"'
        required: true
        default: 'latest'
      confirm:
        description: 'Type "RESTORE" to confirm'
        required: true

jobs:
  rollback:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirm == 'RESTORE' }}
    steps:
      - name: Validate backup_file input
        run: |
          BACKUP_FILE="${{ github.event.inputs.backup_file }}"
          # Only allow "latest" or backup-YYYY-MM-DD.sql.gz.gpg format
          if [[ "$BACKUP_FILE" != "latest" && ! "$BACKUP_FILE" =~ ^backup-[0-9]{4}-[0-9]{2}-[0-9]{2}\.sql\.gz\.gpg$ ]]; then
            echo "Error: Invalid backup_file format. Must be 'latest' or 'backup-YYYY-MM-DD.sql.gz.gpg'"
            exit 1
          fi

      - name: Install 1Password CLI
        uses: 1password/install-cli-action@v2

      - name: Run restore
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
          INPUT_BACKUP_FILE: ${{ github.event.inputs.backup_file }}
        run: |
          # Load secrets (kept in local variables, not exported to GITHUB_ENV)
          SSH_HOST=$(op read 'op://Dev/HETZNER_SERVER_IP/credential')
          B2_KEY_ID=$(op read 'op://Dev/B2_KEY_ID/credential')
          B2_APPLICATION_KEY=$(op read 'op://Dev/B2_APPLICATION_KEY/credential')
          B2_BUCKET_NAME=$(op read 'op://Dev/B2_BUCKET_NAME/credential')
          B2_BUCKET_REGION=$(op read 'op://Dev/B2_BUCKET_REGION/credential')
          BACKUP_ENCRYPTION_KEY=$(op read 'op://Dev/BACKUP_ENCRYPTION_KEY/credential')

          # Setup SSH
          mkdir -p ~/.ssh
          op read "op://Dev/HETZNER_SSH_KEY/private key?ssh-format=openssh" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "$SSH_HOST" >> ~/.ssh/known_hosts 2>/dev/null

          # Determine which file to download
          BACKUP_FILE="$INPUT_BACKUP_FILE"
          if [ "$BACKUP_FILE" = "latest" ]; then
            echo "Finding latest backup..."
            BACKUP_FILE=$(AWS_ACCESS_KEY_ID="$B2_KEY_ID" AWS_SECRET_ACCESS_KEY="$B2_APPLICATION_KEY" \
              aws s3 ls "s3://$B2_BUCKET_NAME/daily/" --endpoint-url "https://$B2_BUCKET_REGION" \
              | sort -r | head -1 | awk '{print $4}')
            if [[ -z "$BACKUP_FILE" ]]; then
              echo "Error: No backup files found in B2 bucket"
              exit 1
            fi
            echo "Found: $BACKUP_FILE"
          fi

          # Download backup from B2
          echo "Downloading: daily/$BACKUP_FILE"
          AWS_ACCESS_KEY_ID="$B2_KEY_ID" \
          AWS_SECRET_ACCESS_KEY="$B2_APPLICATION_KEY" \
          aws s3 cp "s3://$B2_BUCKET_NAME/daily/$BACKUP_FILE" backup.sql.gz.gpg \
            --endpoint-url "https://$B2_BUCKET_REGION"

          # Decrypt and stream to server
          echo "Decrypting and restoring to database..."
          gpg --decrypt --batch --passphrase "$BACKUP_ENCRYPTION_KEY" backup.sql.gz.gpg \
          | gunzip \
          | ssh -i ~/.ssh/deploy_key root@"$SSH_HOST" \
              "docker exec -i aiskualerts-db psql -U aiskualerts -d aiskualerts"

          echo "Restore completed successfully!"

          # Cleanup
          rm -f backup.sql.gz.gpg
          rm -f ~/.ssh/deploy_key
