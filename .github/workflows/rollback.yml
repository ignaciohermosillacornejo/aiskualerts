name: Database Rollback

on:
  workflow_dispatch:
    inputs:
      backup_file:
        description: 'Backup filename (e.g., backup-2026-01-13.sql.gz.gpg) or "latest"'
        required: true
        default: 'latest'
      confirm:
        description: 'Type "RESTORE" to confirm'
        required: true

jobs:
  rollback:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirm == 'RESTORE' }}
    steps:
      - name: Validate backup_file input
        run: |
          BACKUP_FILE="${{ github.event.inputs.backup_file }}"
          # Only allow "latest" or backup-YYYY-MM-DD.sql.gz.gpg format
          if [[ "$BACKUP_FILE" != "latest" && ! "$BACKUP_FILE" =~ ^backup-[0-9]{4}-[0-9]{2}-[0-9]{2}\.sql\.gz\.gpg$ ]]; then
            echo "Error: Invalid backup_file format. Must be 'latest' or 'backup-YYYY-MM-DD.sql.gz.gpg'"
            exit 1
          fi
          echo "BACKUP_FILE=$BACKUP_FILE" >> $GITHUB_ENV

      - name: Install 1Password CLI
        uses: 1password/install-cli-action@v2

      - name: Load secrets
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
        run: |
          echo "SSH_HOST=$(op read 'op://Dev/HETZNER_SERVER_IP/credential')" >> $GITHUB_ENV
          echo "B2_KEY_ID=$(op read 'op://Dev/B2_KEY_ID/credential')" >> $GITHUB_ENV
          echo "B2_APPLICATION_KEY=$(op read 'op://Dev/B2_APPLICATION_KEY/credential')" >> $GITHUB_ENV
          echo "B2_BUCKET_NAME=$(op read 'op://Dev/B2_BUCKET_NAME/credential')" >> $GITHUB_ENV
          echo "BACKUP_ENCRYPTION_KEY=$(op read 'op://Dev/BACKUP_ENCRYPTION_KEY/credential')" >> $GITHUB_ENV

      - name: Setup SSH
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
        run: |
          mkdir -p ~/.ssh
          op read "op://Dev/HETZNER_SSH_KEY/private key?ssh-format=openssh" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "$SSH_HOST" >> ~/.ssh/known_hosts

      - name: Find latest backup if needed
        env:
          AWS_ACCESS_KEY_ID: ${{ env.B2_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ env.B2_APPLICATION_KEY }}
        run: |
          if [ "$BACKUP_FILE" = "latest" ]; then
            echo "Finding latest backup..."
            BACKUP_FILE=$(aws s3 ls "s3://$B2_BUCKET_NAME/daily/" \
              --endpoint-url https://s3.us-west-002.backblazeb2.com \
              | sort -r | head -1 | awk '{print $4}')
            if [[ -z "$BACKUP_FILE" ]]; then
              echo "Error: No backup files found in B2 bucket"
              exit 1
            fi
            echo "Found: $BACKUP_FILE"
            echo "BACKUP_FILE=$BACKUP_FILE" >> $GITHUB_ENV
          fi

      - name: Download backup from B2
        env:
          AWS_ACCESS_KEY_ID: ${{ env.B2_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ env.B2_APPLICATION_KEY }}
        run: |
          echo "Downloading: daily/$BACKUP_FILE"
          aws s3 cp "s3://$B2_BUCKET_NAME/daily/$BACKUP_FILE" backup.sql.gz.gpg \
            --endpoint-url https://s3.us-west-002.backblazeb2.com

      - name: Decrypt and stream to server
        run: |
          echo "Decrypting and restoring to database..."
          # Decrypt locally, decompress, stream to server via SSH, pipe to psql
          gpg --decrypt --batch --passphrase "$BACKUP_ENCRYPTION_KEY" backup.sql.gz.gpg \
          | gunzip \
          | ssh -i ~/.ssh/deploy_key root@"$SSH_HOST" \
              "docker exec -i aiskualerts-db psql -U aiskualerts -d aiskualerts"

          echo "Restore completed successfully!"

      - name: Cleanup
        if: always()
        run: |
          rm -f backup.sql.gz.gpg
          rm -f ~/.ssh/deploy_key
